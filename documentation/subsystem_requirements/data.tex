\subsubsection{Scope}
From the provided requirements specification, the data streaming subsystem, in its most abstract form, is concerned with moving information between two or more entities. However, this subsystem is most fit to satisfy the additional requirement of aggregating and processing location data to generate metadata for user profiling, heatmaps and congestion of routes.

\subsubsection{Technology choices}
The data streaming subsystem can be broken up into 2 main systems, the publish-subscribe messaging system where all the data pours into, and the realtime stream processing system that analyses the data to generate useful metadata.
We will be using components from the Hadoop framework to build the data streaming subsystem. For the first system we will be using Apache Kafka which is a distributed messaging system. For the second system we will be using Apache Storm which is a distributed realtime stream computation system. Due to the distributed nature of these technology choices, they have some very attractive software attributes. See below for a full discussion.

\subsubsection{Software Attributes}

\paragraph{Security}
\mbox{}\\
    Hadoop supports Kerberos network authentication so that when when the system scales to multiple clusters, individual machines cannot be impersonated to compromise the system. Additionally, encryption of network traffic between machines can also seamlessly be enabled to thwart a man in the middle attack as well as access control if that is needed.
\paragraph{Portability}
\mbox{}\\
The subsystem is highly portable, both in terms of operating systems supported as well as seamless failover due to its distributed nature.
\paragraph{Performance}
\mbox{}\\
It is a highly optimised system used by big companies such as Yahoo, Twitter and Pinterest to name a few. Because it is a distributed system, the perfomance needs can always be satisfied by deploying it on more machines. Moreover, the performance scales nearly linearly with the number of machines added to the cluster.
\paragraph{Integrity}
\mbox{}\\
Since it is distributed, if a node fails catastrophically and there is a cluster of nodes, then the failover occurs seamlessly. Additionally, the system can recover from malformed messages and power failures. Due to the above reasons, data integrity as well as the operational integrity of subsystem is very good.

\subsection{Apache Kafka}
The distributed messaging system receives data either through the publisher API or the connector API, depending on the needs and implementation details. This data is published in appropriate topics and subsribers subscribe to the appropriate topic to fulfill its purpose. In this way Kafka fully satisfies the abstract requirements layed out in the provided requirements specification, namely, "the messages and their formats and contents must be independent of the actual carriage medium" and "The data module concerns itself primarily with the act of moving information between the two entities". Additionally, stream management and control can be done by the built in tool Kafka Connect. In particular, UC10 to UC13 are all satisfied by the recommended technology choice.\par
\bigskip
\noindent
As for the specific requirements pertaining to location data and other metadata. The messaging system will have a topic to which position information and the persistent ID of the mobile device will be published to. Furthermore, there will be a metadata topic for heatmaps, another one for congestion and another one for user profiling.
It is important to note that since Kafka serves as a general purpose messaging system which other subsystem may make use of, there is no reason why future improvements on the system must be restricted to the above mentioned topics.
\begin{figure}[h]
    \makebox[\textwidth][c]{\includegraphics[width=1.4\textwidth]{diagrams/data_stream_subsystem/kafka_cluster_use_case.pdf}}
\caption{Kafka use case}
\end{figure}
